---
title: FPGA开发理论知识
description: 知识储备
author: Hatrix
date: 2025-08-31 21:30:00 +0800
categories: [硬件开发]
tags: [实践技能]
math: true
mermaid: true
pin: false
image:
  path: https://cdn.jsdelivr.net/gh/SparkyXXX/Hatrix-s-Blog-Image/img/20240424100647039.png
  alt: FPGA Hardware Architecture
---

## 基本概念

FPGA 是 CLD(Configurable Logic Device，可编程逻辑设备)的一种，一般用于高质量低延迟的视频流处理，硬件加速等，其工作方式与 GPU 类似，将部分在 CPU 上由软件执行的工作 offload 到硬件电路上进行。

FPGA 的结构由可编程输入/输出单元、基本可编程逻辑单元、嵌入式块 RAM、布线资源和 IP 内核单元几部分组成。CLB(Configurable Logic Block，可配置逻辑块) 是 FPGA 的编程部分，也称逻辑单元，配置时可以只对芯片中的部分 CLB 编程，因此一块芯片可以同时执行不同的功能，或以流水线的形式在不同时刻对数据做不同的处理，故 FPGA 拥有很高的并行度。同样由于这一特性，FPGA 的设计目标之一，就是用最少的 CLB 实现需要的逻辑函数。

<img src="https://cdn.jsdelivr.net/gh/SparkyXXX/Hatrix-s-Blog-Image/img/20250619231431328.png" alt="" style="zoom: 50%;" />

CLB 内部由查找表 LUT(Lookup Table)和触发器 FF(Flip-Flops)构成。LUT 是存储真值表的介质，也可用作分布式 RAM 作为快速高效的 on-chip memory。LUT 通过 SRAM 实现编程，可以反复编程且不用刷新电子。今天的 FPGA，内部除了集成了 LUT 和 FF 外，还集成了 RAM(存储资源)、PLL(高速的时钟信号)、DSP(乘法操作、滤波器、数字信号处理)、SERDES(实现高速接口)、CPU(硬核处理器)、NPU(硬核 AI 推理)等硬核 IP 来满足特定应用场景的需求，这样的架构是解决实际问题和成本效率综合考量后的高度优化的结果。

在 Vivado 综合生成的网表中，FDRE/FDCE 是带时钟使能的触发器，分别支持同步复位和同步清零；LDRE/LDCE 是门控锁存器，分别支持复位或清零；CARRY 是 FPGA 内部的快速进位链，用于加法、计数、比较等。除了这些，FPGA 常见的基本原语还包括 LUT(查找表，实现任意逻辑函数)、MUXF/MUXF7/MUXF8(用于多级逻辑选择)、IOBUF(输入输出缓冲器)、BRAM/URAM(片上存储单元)、DSP48(乘加运算单元)、BUFG/BUFR(全局或区域时钟缓冲) 等，它们构成了 FPGA 的核心逻辑、存储和算术单元。网表是电路连接清单，描述了由哪些逻辑单元(门电路、触发器、LUT、RAM、DSP 等)，以及这些单元之间的连线关系(net)。FPGA 芯片就像一张巨大的电路板，除了基本的逻辑单元(LUT、触发器)，大部分面积都被布线资源占据，比如可编程导线和开关，用于连接这些基本逻辑单元。

## ZYNQ 架构

ZYNQ 的 PS 内集成了很多外设控制器模块，如 UART、SPI、I2C、CAN、USB、Ethernet 等，本质上是固化在 ZYNQ 芯片中的硬核外设 IP，是 PS 区域内的逻辑电路。它们存在于 SoC 的 PS 端，与 ARM CPU 核、DDR 控制器、时钟系统等都在同一个芯片中，通过 AXI 总线与 CPU 内核连接，CPU 可以读写寄存器来控制外设。

![](https://cdn.jsdelivr.net/gh/SparkyXXX/Hatrix-s-Blog-Image/img/1671758713977177.png)

ZYNQ 架构分为 ZYNQ-7000 SoC、ZYNQ UltraScale+ MPSoC、ZYNQ UltraScale+ RFSoC 三类。ZYNQ-7000 SoC 的 PS 端为 Cortex A9 的 Arm 核心，为 ARMv7-A 架构，32 位；PL 端为 7 Series 的 FPGA。ZYNQ UltraScale+ MPSoC(MultiProcessor)的 PS 端为 Cortex A53 的 Arm 核心，为 ARM-v8-A 架构，64 位，另外还配备 Cortex-R5F 作为协处理器；PL 端为 UltraScale+的 FPGA。ZYNQ UltraScale+ MPSoC 再往下又可以细分为 CG、EG、EV 三类，面向的硬冲场景不同。ZYNQ UltraScale+ RFSoC(Radio Frequency)与 ZYNQ UltraScale+ MPSoC 的区别仅在于配备了高速 ADC 和 DAC 通道，用于射频领域。APU 是高性能的应用处理单元，是基于 ARM Cortex-A53(64bit)的四核处理器，通常运行 Linux、Petalinux、Yocto 等操作系统；RPU 是实时处理单元，是基于 ARM Cortex-R5F(32bit)的双核处理器，通常运行 FreeRTOS 和裸机程序。

UltraScale+ MPSoC 架构的 PS 端分由 FPD 和 LPD 两个主要电源域/性能域构成，FPD(Full Power Domain)为高性能运算域，包含 APU (Cortex-A53)、GPU、DDR 控制器、FPGA 高性能互联等；LPD(Low Power Domain)为低功耗控制域，包含 RPU (Cortex-R5F)、部分外设(I2C/SPI/UART)、低功耗互联等。

HP 口是 PL 和 PS 之间的 AXI 通道，目的是让 PL 的多个主设备(如 DMA、加速器、视频引擎、网络引擎等)能够高效访问 PS 侧的资源，比如 DDR、AD、DA 等。不同的 HP 口可以配置不同的数据和地址总线宽度以及其它一系列参数。(不同主设备的数据交互接口可能不一样)。多个 HP 可以用于流量隔离(把不同功能流量分到不同口，避免相互干扰)、QoS 策略、简化仲裁/设计(每个 PL 主控对接固定 HP)，或在 PL 侧做 AXI interconnect 后把多个从机合并上 PS。

在 ZYNQ 架构中，PS 端的 DDR 控制器是所有主设备(ARM 核、DMA、加速器等)共享的“唯一通道”，从 PL 过来的访问(通过 HP 口)都是 AXI Master，会竞争 DDR 控制器的访问机会。当多个高带宽的模块(例如视频 DMA、网络 DMA、FFT 加速器)都通过同一个 HP 口访问 DDR 时，多个访问请求(AXI 事务)可能会在一个通道的仲裁器里排队，一个模块的突发传输可能长时间占用通道而其它模块被阻塞，实际 DDR 带宽利用率下降。多个 HP 口的作用在于存在多个独立的 AXI 通道(独立仲裁、独立 FIFO、独立 QoS 设置)，各自的突发访问不会相互阻塞，且支持设置优先级。

ZYNQ 中，PS 端的 ARM 直接有硬件支持的 AXI 接口，而 PL 端需要使用逻辑实现相应的 AXI 协议，Xilinx 提供的现成 IP 如 AXI-DMA、AXI-GPIO、AXI-Datamover、AXI-Stream 都实现了这一接口。ZYNQ 中在 PS 和 PL 之间用硬件实现了九个 AXI 物理接口，包含 AXI-GP0\~AXI-GP3、AXI-HP0\~AXI-HP3、AXI-ACP 共九个。GP 为 32 位接口，理论带宽 600MB/s，两个 PL 主 PS 从，两个 PS 主 PL 从；HP 接口和 ACP 接口可配置为 32 或 64 位接口，理论带宽 1200MB/s，均为 PL 主 PS 从。一个接口的方向性是固定的，要么能发起事务，要么只能响应事务。每个物理接口支持的协议也是确定的，HP 和 ACP 接口支持 AXI4 协议，GP 接口支持 AXI4 和 AXI4-Lite 协议，而 AXI4-Stream 协议是纯 PL 内部的连接方式，需要用 AXI-DMA 或其它类似模块在 PL 内部实现 AXI4 到 AXI4-Stream 的转换。ACP 与 HP 接口的区别在于 ACP 可以保证与 CPU Cache 的一致性。

## 存储资源

FPGA 中常用的逻辑存储结构有 RAM、ROM 和 FIFO，三种结构 Xilinx 都提供了成熟的 IP，具体使用查阅文档即可。RAM 和 ROM 的 IP 有 Distributed Memory Generator 和 Block Memory Generator 两个，区别在于生成的 Core 所占用的 FPGA 资源不一样，从 Distributed Memory Generator 生成的 RAM/ROM Core 占用的资源是 LUT；而从 Block Memory Generator 生成的 RAM/ROM Core 占用的资源是 Block Memory。

Block Memory 是 FPGA 中片上块状存储资源的统称，是逻辑上的概念。Block Memory 主要由 BRAM 实现，少数型号的 FPGA 也有 URAM 和 HBM。BRAM 即 Block RAM，是 FPGA 中固化的硬件存储单元，固定容量为 18K bits(18432 bits)，可以单独使用也可以两个相邻的 18k BRAM 组合成双口 36k BRAM。设计中调用的资源以 BRAM 为最小单位，向上取整。例如存储位宽为 16 位，数据深度为 512，总共占用 16\*512 = 8192 bits = 1KBytes。数据宽度指一个数据占用的 bit 位数，数据深度指可以存放的数据个数。数据深度与地址线宽度有关，如数据深度为 512，则对应的地址线为 9 位，$$2^9=512$$。

RAM 和 ROM 中任意一个存储单元都可以在相同时间内被访问，硬件上由存储单元阵列 + 地址译码器 + 读写电路构成；ROM 由 RAM 配合要预先写入的 coe 文件实现。FIFO 是先进先出队列存储器，内部常用环形缓冲区的结构，由 RAM+读写指针实现。根据读写时钟，可以分为同步 FIFO 和异步 FIFO，同步 FIFO 的读写时钟相同，异步 FIFO 的读写时钟不同。

FIFO 不像 RAM 那样可以随意访问地址，而是写入只能写到队尾，读出只能从队首读取，硬件自动维护顺序，读写顺序固定。FIFO 的容量一般比较小，广泛用于数据的缓存、平衡异步时钟域之间的速度差等。读写对象为读写指针指向的存储单元，读写时操作指针位置，FIFO 内部逻辑负责防止读空或写满。FIFO 不能重复读出数据，也不能覆盖数据，没有地址的概念，由 full、empty 信号进行数据流控制；RAM 则反之。

FIFO Generator 是队列，Block Memory Generator 是随机访问内存。FIFO 用于不同时钟域之间的数据传输(CDC FIFO)、生产者和消费者速度不一致的数据缓冲、流式数据接口缓存；Block Memory 用于需要随机读写的数据存储、查找表、数据缓存等。FIFO 支持异步时钟，只需要告诉它读或写；Block Memory 一般只支持同步时钟，需要管理地址、何时读写。FIFO 更偏向流式、Block RAM 更偏向存储。FIFO Generator 中的实现资源分时钟域和存储资源两方面，时钟域有同步和异步之分，存储资源可选 BlockRAM、Distributed RAM、Shift Reg、Built-in FIFO。

## 时钟资源

锁相环(PLL)是 FPGA 中的时钟资源资源，通过 PLL 可以由晶振的频率引出许多不同的频率供各种外设使用。FPGA 使用专用的全局和局部 IO 以及时钟资源来管理各种时钟需求。FPGA 中的时钟不能直接裸信号使用，也不能走普通的布线逻辑，而需要经过专用的 buffer 电路驱动到全局或区域的时钟网络，这称为时钟 buffer。buffer 的作用主要是提高驱动能力和保证延迟均衡。

FPGA 内部有大量可编程的互连资源，逻辑单元之间的信号通过这些线段和开关连接，称为布线逻辑 (routing fabric)。普通布线逻辑指这些通用的互连通道，用来传数据/控制信号。它们延迟大、路径长短不一、受布线工具优化影响。时钟如果走普通布线逻辑 → 延迟和 skew 无法保证，会导致严重的同步问题。时钟倾斜 skew 是指同一个时钟信号到达不同触发器的时间差。如果 skew 太大，可能导致 setup/hold 时间被破坏 → 数据寄存错误。因此需要使用专用的时钟 buffer + 全局时钟网络(时钟布线网络)，把 skew 控制在几十皮秒的范围内。

![](https://cdn.jsdelivr.net/gh/SparkyXXX/Hatrix-s-Blog-Image/img/20250928134917750.png)

- 全局时钟资源指 FPGA 内部专门布设的低延迟、低偏斜的长距离布线网络，保证一个时钟信号可以同时驱动全芯片的逻辑，对应的 buffer 为 BUFG(Global Clock Buffer)，用于驱动全局时钟，如系统主时钟、DDR 时钟等。

- 区域时钟资源限定在芯片的一部分，对应的 buffer 为 BUFH(Horizontal buffer)和 BUFR(Regional buffer)，用于驱动局部时钟，减少功耗和浪费。FPGA 不允许随便用普通布线逻辑来传时钟，因为普通布线延迟大且不均衡，会导致时钟偏移，因此 Xilinx 给时钟单独做了专用的全局和局部 IO 与时钟资源。

CMT(Clock Management Tiles)分布在 FPGA 中的不同位置，提供了时钟合成、倾斜矫正和过滤抖动等功能，每个 CMT 包括一个 MMCM(Mixed Mode Clock Manager)和一个 PLL(Phase Lock Loop)。PLL 通过锁相机制使输出时钟和输入时钟相位一致，可实现分频和倍频，缺点是相位控制粒度有限。MMCM 比 PLL 功能更强，可实现分数分频/倍频和更精准的相移。CMT 的输入可以是 BUFR、IBUFG、BUFG、GT、BUFH 和本地布线，MMCM 或 PLL 输出的是原始时钟信号，要驱动 FPGA 内部逻辑，还需要接入专用时钟网络(BUFG/BUFH)。

时钟 buffer/网络说明：

- IBUFG (Input BUFG)：把外部引脚的时钟(从 IO pin 来的时钟)引入到 FPGA 内部，送入全局/区域时钟网络。
- BUFG (Global BUFG)：驱动全局时钟网络，确保整个芯片时钟到达几乎同时。
- BUFH (Horizontal Buffer)：区域时钟 buffer，只在本 region(一般是一个 clock region，高度 50 CLB 左右)内部传播。
- BUFR (Regional BUFR)：区域时钟 buffer，常用于 I/O 时钟(比如串行接口的本地时钟)。
- GT (Gigabit Transceiver)：高速收发器自带的时钟输出，可作为 CMT 的时钟源。
- 本地布线 (Local routing)：如果你把时钟当普通信号布线，会走 LUT/普通 interconnect，延迟和偏斜不可控。

在 Utility Buffer 这个 IP 中，可以选择 C Buf Types，这是一系列用于信号缓冲与时钟管理的硬件原语，其中 IBUFDS 为差分输入缓冲器，可将外部差分信号转换为内部单端信号，适用于高速数据或时钟的差分输入；OBUFDS 是差分输出缓冲器，能将内部单端信号转换为差分信号输出，常用于高速接口的信号发送；IOBUFDS 为三态差分 I/O 缓冲器，支持双向差分信号传输；IBUFDSGTE 专为高速收发器设计，用于高速 BANK 的参考时钟输入，具备增益和偏置调整能力；BUFG 是全局时钟缓冲器，可低延迟、低抖动地驱动全局时钟网络；BUFH 用于驱动单个时钟区域内的水平时钟线，实现区域内低偏斜传输；BUFGCE 是带使能端的全局时钟缓冲器，可灵活控制全局时钟输出；BUFHCE 则是带使能端的水平时钟缓冲器，用于单个时钟区域内时钟的使能管理。

## IO 资源

MIO 和 EMIO 是 ZYNQ 中 PS 端的 IO 资源。Bank 是可编程逻辑芯片中对芯片内功能相近或关联的硬件资源进行物理分区和管理的单元，一般指 IO Bank。FPGA 芯片的管脚被划分为多个 IO Bank，每个 Bank 有一组外部供电的电源引脚，PS 的 IO 和 PS 的 MIO 都分布在若干个 Bank 中，每个 Bank 有独立的电平标准。在 FPGA 进行引脚分配时，必须先明确每个 IO Bank 的电源电平、支持的接口标准和资源限制(如是否带 PLL)。

MIO (Multiplexed IO)是 PS 端提供的物理 IO 管脚，可以连接诸如 UART、SPI、I2C、GPIO 等，通过 Vivado 软件设置可以将信号通过 MIO 导出。也可以将信号通过 EMIO 连接到 PL 端的 FPGA fabric，再从 PL 的 I/O Bank 的管脚引出。EMIO 是 PS 端的信号(注意不是来自 PS 封装的 MIO 引脚)通过 AXI 接口暴露到 PL 侧的一组逻辑 GPIO 接口，来源是 PS 内部信号，是直接逻辑线，不是直接的物理引脚。这样的逻辑线接入 IOBUF 之后，才成为 PL 端可以实际操作的物理引脚。

AXI GPIO 模块可以定义两个 GPIO 通道独立工作，且使用 Board Interface 可以不用手动添加相应的管脚约束。AXI GPIO 相较于 EMIO 的好处是，可以将多个 GPIO 当作总线一起控制；EMIO 则比较适合单个 GPIO 信号的控制。可以使用 AXI GPIO 的 IP 核，通过 AXI 总线控制 PL 端信号。AXI GPIO 是 xilinx 提供的 PL 侧的外设 IP 核，作用是让 PS 通过 AXI 总线访问 PL 端的 GPIO，因此使得 PS 端可以访问到 PL 端的信号。AXI GPIO 来源是 PL 内部逻辑，PS 通过 AXI 寄存器访问 PL GPIO，读写过程需要 AXI 总线。

## 运算资源

一些运算类的 IP，实现方式可以选用 Fabric 和 DSP48，前者是 FPGA 通用的逻辑资源，包括查找表、触发器、多路选择器等基础逻辑单元。特点是功能灵活，可实现任意数字逻辑，但运算性能(速度、功耗)相对较低，且复杂运算(如乘法、乘加)会消耗大量 LUT 资源。适用于简单逻辑运算(如小规模加法、逻辑门组合)、控制类电路，或在 DSP48 资源不足时的 “兜底” 实现。后者是专用的硬核数字信号处理器，是 FPGA 内置的专用数字信号处理模块(如 Xilinx 的 DSP48E 系列)，集成了乘法器、累加器、ALU 等专用电路。特点是针对高速算术运算(乘法、乘加、滤波、FFT 等)做了硬件优化，具有高频率、低功耗、资源高效的特点(一个 DSP48 可替代数百个 LUT 实现乘法)，适用于高性能数字信号处理场景，如 FIR/IIR 滤波器、复数乘法、矩阵运算、神经网络加速等，需要密集算术运算的领域。DSP Slice 是 DSP48 系列硬核的最小功能模块，是构成复杂 DSP 单元的基础，集成了高速乘法器、加法器、累加器、多路选择器和控制逻辑等最核心的算术运算组件。

## xdc 文件和约束

### xdc 文件

xdc 文件用于存放约束，约束分物理约束和时序约束两类。物理约束包括 IO 接口约束、布局约束、布线约束、配置约束；时序约束涉及 FPGA 内部各种逻辑或走线的延时。

在最佳实践中，建议以约束集（一个 constraint 目录）为单位管理 xdc 文件，其中分 pins.xdc 和 timing.xdc，前者用于配置引脚 IO 等物理约束，后者专门用于配置时序约束。除了直接编写 xdc 文件，也可以通过 GUI（Constraint Wizard 和 Edit Timing Contraint）的方式设置约束，后由 EDA 将 GUI 设置的结果自动写入 xdc 文件。实际使用中，往往用 GUI 设置时序约束，而物理约束一般直接修改 xdc 文件。

xdc 文件中按照约束的先后顺序依次执行，针对同一个管脚或同一个时钟时钟的不同约束，只有最后一条约束生效。除了先后顺序之外，约束还有优先级。对于同样的约束，定义越精细则优先级越高。

### 物理约束

物理约束相对简单，普通 IO 口只需约束引脚号和电压，注意大小写，端口名称是数组的话用{ }括起来，端口名称必须和源代码中的名字一致，且不能和关键字一样。

- 管脚约束：`set_property PACKAGE_PIN 引脚编号 [get_ports 端口名称] `
- 电平信号约束：`set_property IOSTANDARD 电平标准 [get_ports 端口名称]`。

```verilog
set_property PACKAGE_PIN J16 [get_ports {led[3]}]
set_property PACKAGE_PIN K16 [get_ports {led[2]}]
set_property PACKAGE_PIN M15 [get_ports {led[1]}]
set_property PACKAGE_PIN M14 [get_ports {led[0]}]
set_property PACKAGE_PIN N15 [get_ports rstn]
set_property PACKAGE_PIN U18 [get_ports clk]

set_property IOSTANDARD LVCMOS33 [get_ports {led[3]}]
set_property IOSTANDARD LVCMOS33 [get_ports {led[2]}]
set_property IOSTANDARD LVCMOS33 [get_ports {led[1]}]
set_property IOSTANDARD LVCMOS33 [get_ports {led[0]}]
set_property IOSTANDARD LVCMOS33 [get_ports rstn]
set_property IOSTANDARD LVCMOS33 [get_ports clk]
```

`BOARD_PIN` 是 Vivado 板级接口约束(Board Interface Constraint)系统的一部分属性。它不是约束 FPGA 封装引脚的“物理约束”(比如 `PACKAGE_PIN`)， 而是 Vivado 板卡定义(Board Definition)机制中自动生成的“逻辑绑定信息”。Vivado 的 Board 文件系统允许：选择某块开发板(如 ZCU102、ZedBoard、VC707)；然后直接把 IP 的接口(如 AXI GPIO、UART、I2C)连接到 板卡接口(Board Interface)；Vivado 自动知道这些接口应该连到哪个物理引脚、使用什么 IOSTANDARD。这种自动化的“板卡接口”约束就叫 Board Interface Constraint，它在内部通过命令实现：

```verilog
set_property BOARD_PIN "some_pin_name" [get_ports <port_name>]
```

### 时序约束

时序约束的目的，为了满足建立时间和保持时间的要求，由于 RTL 代码中是不包含时序信息的，因此需要时序约束来告诉 EDA 软件这些时序上的前提条件。时钟过约束或欠约束都可能导致时序难以收敛，因此需要设定合理的时序约束。

先介绍一些基本概念：

- 同步时钟和异步时钟：时钟有同步时钟和异步时钟之分，同步时钟是指时钟源相同，频率相位有一定关系的时钟；否则（即时钟源不同，频率和相位没有任何关系；因为自然界没有任何两个完全相同的晶振，因此不同源时钟的频率和相位没有任何关系）为异步时钟。在不做任何时序约束的情况下，vivado 默认所有时钟均为同步时钟，会对所有路径进行分析，因此存在异步时钟的情况下，需要对其进行时钟约束。

- 建立时间和保持时间：建立时间是指时钟上升沿到来之前，数据必须保持稳定的时间；保持时间是指时钟上升沿到来之后，数据必须保持稳定的时间。保存时间的意义在于源寄存器的输出不能太快到达目标寄存器，以防止新数据冲掉原来的数据。保持时间是对当前时钟沿而不是下一个时钟沿的约束。由于数据在时钟的上升沿被锁存，因此数据需要在时钟的上升沿的建立时间和保持时间内稳定不变。

  ![image-20251213230104938](../assets/post-pics/image-20251213230104938.png)

  建立时间和保持时间由器件特性决定，决定了使用哪个 FPGA 之后，建立时间和保持时间也就随之确定。Xilinx FPGA 的建立时间和保持时间分别在 0.04ns 和 0.2ns 的量级，不同器件略有差异，具体可查阅器件的 DC and AC Switching Characteristics。

- 建立时间关系和保持时间关系：建立时间关系是指当前数据从源寄存器的时钟启动沿到达目的寄存器的时钟锁存沿所用的这段时间，满足当前数据被锁存的建立时间。保持时间关系是指当前数据从源寄存器的时钟启动沿到达目的寄存器的时钟锁存沿所用的这段时间，满足上一个数据被锁存的建立时间。

- 启动沿和锁存沿：启动沿指传输到源寄存器的时钟沿，锁存沿指传输到目标寄存器的时钟沿。从时间上看，启动沿比锁存沿早一个时钟周期。实际上，启动沿和锁存沿是同一个时钟周期由时钟沿传输来的时钟信号。

- 数据到达路径和数据需求路径：数据到达路径是指数据在两个寄存器间传输的实际路径，由此可推算出数据在两个寄存器间传输的实际时间。数据到达路径的起点是时钟沿，经过源寄存器的时钟输入端口、源寄存器的数据输出端口，最终到达目的寄存器的输入端口。数据需求路径是指为了确保稳定可靠且有效的传输（即满足相应的建立时间和保持时间要求），数据在两个寄存器之间传输的理论所需时间的计算路径。数据需求路径的起点也是时钟源，终点是目的寄存器的时钟输入端口。

  ![image-20251210145804924](../assets/post-pics/image-20251210145804924.png)

FPGA 中的时序路径有四种：一是从输入端口到 FPGA 内部第一级触发器的路径，用 `set_input_delay` 指令约束；二是 FPGA 内部触发器之间的路径，用 `create_clock` 指令约束；三是 FPGA 内部末级触发器到输出端口的路径，用 `set_output_delay` 约束；四是 FPGA 输入端口到输出端口的路径，用 `set_max_delay` 约束。四种路径中，一般最关心的是第二种，即 FPGA 内部的时序逻辑。

![image-20251214212000690](../assets/post-pics/image-20251214212000690.png)

典型的时序模型如下。完整的时序路径包括源时钟路径、数据路径和目的时钟路径，也可以表示为触发器+组合逻辑+触发器的模型。

![image-20251214212720165](../assets/post-pics/image-20251214212720165.png)

时钟模型要求的两个公式如下，其中 $$T_{\text{clk}}$$ 为系统所能达到的最小时钟周期，$$T_{\text{co}}$$ 为源寄存器时钟到输出的时间，$$T_{\text{logic}}$$ 为组合逻辑延迟，$$T_{\text{routing}}$$ 为两级寄存器之间的布线延迟，$$T_{\text{su}}$$ 为建立时间，$$T_{\text{h}}$$ 为保持时间，$$T_{\text{skew}}$$ 为时钟倾斜。$$T_{\text{co}}$$、$$T_{\text{su}}$$、$$T_{\text{h}}$$ 都取决于芯片工艺，在 FPGA 芯片型号选定后就确定了，因此确定芯片后，只能通过 $$T_{\text{logic}}$$ 和 $$T_{\text{routing}}$$ 来改善 $$T_{\text{clk}}$$。其中 $$T_{\text{logic}}$$ 取决于 RTL 代码设计，$$T_{\text{routing}}$$ 取决于布局布线策略。$$T_{\text{skew}}$$ 在同步时钟设计中一般忽略，因为 FPGA 中的时钟树会尽量保证到达每个寄存器的延迟相同。

$$
\begin{aligned}
&T_{\text{clk}} \geqslant T_{\text{co}} + T_{\text{logic}} + T_{\text{routing}} + T_{\text{setup}} - T_{\text{skew}}\\
&T_{\text{co}} + T_{\text{logic}} + T_{\text{routing}} \geqslant T_{\text{h}} + T_{\text{skew}}
\end{aligned}
$$

![image-20251214214938561](../assets/post-pics/image-20251214214938561.png)

最常用的时序约束是时钟约束，时钟约束又有许多分类。

- 源时钟/主时钟约束用来设置主时钟是多少兆 Hz，用 create clock 指令设置。主时钟通常有两种情况，一种是由外部时钟沿提供，通过时钟管脚进入 FPGA，该时钟引脚绑定的时钟为主时钟；另一种是高速收发器 GT 的时钟 RXOUTTCLK 或 TXOUTTCLK。
- 衍生时钟约束包括自定义时钟和自动生成的时钟，自定义时钟如自己写的分频器、倍频器，需要设置约束；自动生成的时钟如 MMCM、PLL、BUFR、debug_hub 生成的时钟，不需要自己约束。衍生时钟用 create generated clock 指令约束。
- 异步时钟约束和互斥时钟约束用 set clock group 指令设置，其中互斥时钟又分物理互斥和逻辑互斥，物理互斥指引脚不同的时钟，逻辑互斥则是用 mux 组织的时钟。物理互斥可用于验证同一个时钟端口在不同时钟频率下是否获得时序收敛。逻辑互斥是在使用 NUFGMUX 时，会有两个输入时钟，但只会有一个时钟被使用。

输入延迟约束和输出延迟约束分别用 `set_input_delay` 和 `set_output_delay` 指令实现，其时钟源可以是时钟输入管脚或虚拟时钟。另外，输入延迟约束和输出延迟约束并不起到延迟的作用，而是对周期的约束。比如输入延迟约束用于用于告诉 vivado 输入数据和输入时钟之间的延迟关系；而想要调节输入信号延迟，则需要使用 IDELAY 硬件资源。最大最小延迟约束用 `set_max_delay` 和 `set_min_delay` 实现，最大最小延迟的主要应用场景有二：一是输入管脚的信号经过组合逻辑之后直接输出到管脚；二是异步电路之间的最大最小延迟。下图以输入延迟为例进行说明。

![image-20251214222348267](../assets/post-pics/image-20251214222348267.png)

虚拟时钟没有与之绑定的物理管脚，通常用于设定输入和输出的延迟约束，主要用于以下三个场景：一是外部 IO 的参考时钟并不是设计中的时钟；二是 FPGA/IO 路径参考时钟来源于内部衍生时钟，但与主时钟的频率关系并不是整数倍；三是针对 IO 指定不同的 jitter 和 latency。总结来说，之所以要创建虚拟时钟，对于输入来说，是因为输入到 FPGA 数据的捕获时钟是 FPGA 内部产生的，与主时钟频率不同，或者 PCB 上有 Clock Buffer 导致时钟延迟不同。对于输出来说，下游器件只接收到 FPGA 发送过去的数据，并没有随路时钟，要用自己内部的时钟去捕获数据。另外，虚拟时钟必须在约束 IO 之前被定义。

两种时序例外，一种是多周期路径。保持时间的检查，默认是在建立时间的前一个周期进行的。但若出现路径过长或逻辑延长过长需要经过多个时钟周期才能到达目标寄存器；又或者在数据发起的几个周期之后后续逻辑才能使用，此时如果按照单周期路径进行时序检查，就会报时序违规，因此需要使用多周期约束的指令来设置。另一种是伪路径，伪路径指路径存在但该路径的功能不会发生或无需时序约束。创建伪路径可以减少工具运行优化的时间，增强实现结果。伪路径一般用于跨时钟域、一上电就被写入数据的寄存器、异步复位或测试逻辑、异步双端口 RAM，即主要用在异步时钟的处理上。

## AXI 协议

AXI 全称 Advanced eXtensible Interface，是 ARM 提出的 AMBA 协议标准的一部分，Xilinx 从 6 系列的 FPGA 开始引入这一协议。AXI 属于片上总线协议，描述主设备和从设备之间的数据传输方式，通过 VALID 和 READY 信号的握手机制建立主从设备之间的连接(VALID 来自主设备，READY 来自从设备)。任意通道上完成一次数据交互都称为一个传输 transfer，当 VALID 和 READY 信号均为高电平时到来时钟上升沿，就会发生传输。一个通道内 VALID 和 READY 信号的建立顺序无关紧要。VALID/READY 机制使得数据的发送和接受方都有能力控制传输速率。

ZYNQ 中使用的主要是 AXI4 协议族，包括 AXI4、AXI4-Lite、AXI4-Stream 三种协议。(注：burst 指一个地址中可发生多次数据传输的传输事务，burst 操作只需要提供首地址)

- AXI4：存储器映射总线，采用内存映射控制，支持 burst 传输，高带宽，适合访问块式内存，常用于 DDR 等大量数据读写。

- AXI4-Lite：存储器映射总线，采用内存映射控制，仅支持单数据传输，常用于访问和配置状态寄存器。
- AXI4-Stream：连续流式接口，没有地址的概念，支持 burst 传输，适合访问流式内存，常用于视频流、FFT 数据等流式数据通路。

![](https://cdn.jsdelivr.net/gh/SparkyXXX/Hatrix-s-Blog-Image/img/servlet.png)

块式内存和流式内存是两种数据传输模型，块式数据的数据按照地址排列，一次访问一大块数据，典型的访问方式是内存地址+长度，如 DDR / PS 内存存储、CPU 内存搬运等。流式数据的数据不需要地址，一次访问一个元素，一个接一个，典型的方式是按时间按拍数，如 FPGA 内部视频像素流、FFT 数据流等流水线模块处理。AXI 或 AXI Lite 的块式访问和 AXI Stream 的流式访问是 ZYNQ 架构中最常见的桥接，桥接(Bridge)是指将两种不同协议/总线类型互相转换，让它们可以通信。最典型的场景是 PS 端的 DDR 为 AXI 的 Memory Mapped，而算法模块为 Stream。

AXI4 和 AXI4-Lite 中，将一次传输事务分为五个独立通道，分别为读地址 AR、读数据 R、写地址 AW、写数据 W 和写响应 B。每个通道各有一组独立的信号线(各信号线的具体含义这里不一一列出)，有一个独立的 AXI 握手协议，因此 AXI 协议支持同时进行读写操作。AXI4-Stream 由于没有地址的概念，因此也仅定义了一条通道，完成握手和数据传输。

![](<https://cdn.jsdelivr.net/gh/SparkyXXX/Hatrix-s-Blog-Image/img/servlet%20(1).png >)

虽然 AXI 协议的五个通道是独立并行的，但并非完全没有逻辑时序约束。AXI 协议要求读通道中读数据位于读地址之后，具体来说是 AR 通道地址有效之后才会返回 R 通道 VALID；类似地，要求写响应位于写通道中地最后一次写入传输之后，具体来说是 B 通道 VALID 只能在最后一个 W 通道地数据拍结束之后才出现。不过，这样的约束是通过 READY 和 VALID 信号实现的，设计时无需考虑地址和数据的先后顺序，较为灵活，只要保证符合 READY 和 VALID 信号的握手机制即可。

AXI 协议的一些特性如下：

- AXI 允许读数据返回之前，又发起一次新的读请求，类似于流水线的概念。延迟较大的情况下，可以做到不影响带宽，将延迟掩盖起来。
- 支持非对齐传输：传输的地址和数据宽度一致时称为对齐传输，地址是字节地址的情况下，假设总线数据宽度为 32bit(4 字节)每次访问的起始地址是 4 的倍数，那么就是对齐的。而 AXI 协议通过 WSTRB 的掩码机制，每一位对应一个字节，可以控制只写入部分字节，因此写传输可以起始于任意地址，不必是 4 字节边界。
- ARSIZE 和 ARBURST 分别规定了单次传输的数据宽度(如 4 字节、8 字节等)和突发类型(FIXED 地址固定、INCR 地址按固定值递增、WRAP 地址递增但循环)。写通道同样有这样的信号。
- 支持不同 ID 之间的乱序传输，同一个 ID 内则是保序的。AXI4 中已经取消了 WID 信号的使用，不再支持写乱序。
- AXI 协议是一个点对点的主从接口，当多个外设需要相互交互数据时，需要加入 AXI Interconnect 模块(Xilinx 提供了相应的 IP)，本质上是一个实现交换机制的互联矩阵

## Xilinx 产品线

FPGA 和 SoC 是 Xilinx 的两大主要产品系列。

FPGA 即纯 FPGA 芯片，按照工艺节点分为 UltraScale+(16nm)、UltraScale(20nm)、7 Series(28nm)三大类，类似于 CPU 中第几代的概念。在每个类别中，又分为 Spartan、Artex、Kintex、Virtex 四个子系列，面向不同的应用场景和市场定位，性能依次提升。

![](https://cdn.jsdelivr.net/gh/SparkyXXX/Hatrix-s-Blog-Image/img/1027237-120PGJ409196.jpg.crdownload)

除了最新的 Versal ACAP(Adaptive Compute Acceleration Platform，自适应计算加速平台)之外，Xilinx 将 SoC 系列命名为 ZYNQ 计算架构，是 FPGA + Arm 的多处理器系统，集成了 FPGA 的可编程逻辑(PL)与 ARM 处理器核心(PS)，两者之间通过 AXI(Advanced eXtensible Interface)总线实现低延迟数据传输。PS 具有固定的架构，包含了处理器和系统的存储器，适合控制或具有串行执行特性的部分以及浮点计算等；而 PL 是完全灵活的，适合并行流处理。

## 参考资料

[芯片是什么](https://zhuanlan.zhihu.com/p/21358006)

[FPGA 的架构和工具解析](https://zhuanlan.zhihu.com/p/427787229)

[ZYNQ Soc 介绍](https://fpga.eetrend.com/content/2022/100567012.html)

[时序约束 1](https://www.bilibili.com/video/BV1ME41127So/)

[时序约束 2](https://www.bilibili.com/video/BV1Be4y137Qo/)
